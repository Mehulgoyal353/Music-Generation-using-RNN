{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehulgoyal353/Music-Generation-using-RNN/blob/main/Music_generation_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIgp02gJJ56r"
      },
      "source": [
        "#Importing required libraries\n",
        "This model is trained to learn the patterns in raw sheet music in [ABC notation](https://en.wikipedia.org/wiki/ABC_notation) and then use this model to generate new music.\n",
        "\n",
        "Comet has been used to track the model development and training runs. The personal API key is generated after logging into [Comet ML](https://www.comet.com/docs/v2/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD8wxpLyamHz"
      },
      "outputs": [],
      "source": [
        "!pip install comet_ml > /dev/null 2>&1\n",
        "import comet_ml\n",
        "COMET_API_KEY = \"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "!pip install mitdeeplearning --quiet\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "from scipy.io.wavfile import write\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "\n",
        "assert COMET_API_KEY != \"hce3AJwsDNoJJq1rxvSoGTxwc\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aaIJq9UBV-l"
      },
      "source": [
        "#Downloading and inspecting the dataset\n",
        "This dataset involve a large collection of Irish music. It is downloaded using the mdl library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv71CR1bd9CK"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "songs = mdl.lab1.load_training_data()\n",
        "\n",
        "# Print one of the songs to inspect it in greater detail!\n",
        "example_song = songs[0]\n",
        "print(\"\\nExample song: \")\n",
        "print(example_song)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Loading the dataset\n",
        "songs = mdl.lab1.load_training_data()\n",
        "\n",
        "# Define a function to parse song details\n",
        "def parse_song(song_text):\n",
        "    song_details = {}\n",
        "    lines = song_text.split('\\n')\n",
        "    for line in lines:\n",
        "        if line.startswith('X:'):\n",
        "            song_details['id'] = line[2:].strip()\n",
        "        elif line.startswith('T:'):\n",
        "            song_details['title'] = line[2:].strip()\n",
        "        elif line.startswith('M:'):\n",
        "            song_details['meter'] = line[2:].strip()\n",
        "        elif line.startswith('L:'):\n",
        "            song_details['length'] = line[2:].strip()\n",
        "        elif line.startswith('K:'):\n",
        "            song_details['key'] = line[2:].strip()\n",
        "    return song_details\n",
        "\n",
        "# Parse all songs\n",
        "parsed_songs = [parse_song(song) for song in songs]\n",
        "\n",
        "# Specify the CSV file name\n",
        "csv_file = 'songs.csv'\n",
        "\n",
        "# Writing to CSV file\n",
        "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=['id', 'title', 'meter', 'length', 'key'])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(parsed_songs)\n",
        "\n",
        "print(f\"Data successfully written to {csv_file}\")\n"
      ],
      "metadata": {
        "id": "BKe98KUwEf_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ttG7GZB_ET"
      },
      "source": [
        "The mdl library also has functions to convert the strings into wav files which can be listened to on colab itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRMzOEsTfHvb"
      },
      "outputs": [],
      "source": [
        "# Convert the ABC notation to audio file and listen to it\n",
        "mdl.lab1.play_song(example_song)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgiPNkbjChQj"
      },
      "source": [
        "The ABC notation of these songs doesn't only contain information about the notes being played, but **also has the meta information** like the song title, key and tempo. Thus we get the possible characters in the dataset separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENQrf4YcfU68"
      },
      "outputs": [],
      "source": [
        "# Join the list of song strings into a single string containing all songs\n",
        "songs_joined = \"\\n\\n\".join(songs)\n",
        "\n",
        "# Find all unique characters in the joined string\n",
        "vocab = sorted(set(songs_joined))\n",
        "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up0Nt-CoDXJM"
      },
      "source": [
        "The aim is for the RNN model to learn patterns in ABC music, and then use this model to generate (i.e., predict) a new piece of music based on this learned information.\n",
        "\n",
        "Henceforth, what is required from the model is: **given a character, or a sequence of characters**, what is the **most probable next character**.\n",
        "\n",
        "RNNs maintain an **internal state that depends on previously seen elements**, so **information about all characters seen up until a given moment will be taken into account in generating the prediction**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2htaheVFE_XS"
      },
      "source": [
        "#Vectorization and Processing\n",
        "Before training the RNN model, **numerical representations** of the text based dataset need to be created.\n",
        "\n",
        "For this **two lookup tables** can be created: **one that maps characters to numbers, and a second that maps numbers back to characters.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HmyB4IO_gIbM"
      },
      "outputs": [],
      "source": [
        "### Define numerical representation of text ###\n",
        "\n",
        "# Create a mapping from character to unique index.\n",
        "# For example, to get the index of the character \"d\", `char2idx[\"d\"]` can be evaluated.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "\n",
        "# Create a mapping from indices to characters. This is\n",
        "# the inverse of char2idx and allows the user to convert back\n",
        "# from unique index to the character in the vocabulary.\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyWKMm5DgMwj"
      },
      "outputs": [],
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kgryUrP6g0h5"
      },
      "outputs": [],
      "source": [
        "### Vectorize the songs string ###\n",
        "\n",
        "def vectorize_string(string):\n",
        "  # Convert each character in the string to its corresponding index\n",
        "  vectorized = [char2idx[char] for char in string]\n",
        "  # Convert the list to a numpy array\n",
        "  return np.array(vectorized)\n",
        "\n",
        "vectorized_songs = vectorize_string(songs_joined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIOD3valhNpS"
      },
      "outputs": [],
      "source": [
        "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
        "# check that vectorized_songs is a numpy array\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to actually divide the text into example sequences that will be used during training. Each input sequence fed into the RNN will contain `seq_length` characters from the text. A **target sequence** for each input sequence also need to be defined, which will be used in **training the RNN to predict the next character**.\n",
        "\n",
        "For each input, the corresponding target will contain the same length of text, except **shifted one character to the right**.\n",
        "\n",
        "To do this, the text is borken into chunks of `seq_length + 1`. For example, if `seq_length` is 4 and our text is \"Hello\". Then, the input sequence is \"Hell\" and the target sequence is \"ello\".\n",
        "\n",
        "#Creating Training examples and targets\n",
        "Using the *Batch Method*, the **stream of character indices can be converted into sequences of desired size**.\n",
        "\n",
        "To know more about the Batch Method: https://visualstudiomagazine.com/articles/2014/08/01/batch-training.aspx"
      ],
      "metadata": {
        "id": "aYHWNLQEISsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eERfU26eksbp"
      },
      "outputs": [],
      "source": [
        "### Batch definition to create training examples ###\n",
        "\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  # the length of the vectorized songs string\n",
        "  n = vectorized_songs.shape[0] - 1\n",
        "  # randomly choose the starting indices for the examples in the training batch\n",
        "  idx = np.random.choice(n-seq_length, batch_size)\n",
        "\n",
        "  # Construct a list of input and output sequences for the training batch\n",
        "  input_batch = [vectorized_songs[i:i + seq_length] for i in idx]\n",
        "  output_batch = [vectorized_songs[i + 1:i + seq_length + 1] for i in idx]\n",
        "\n",
        "  # x_batch, y_batch provide the true inputs and targets for network training\n",
        "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "  return x_batch, y_batch\n",
        "\n",
        "\n",
        "# Perform some simple tests to make sure your batch function is working properly!\n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args):\n",
        "   print(\"======\\n[FAIL] could not pass tests\")\n",
        "else:\n",
        "   print(\"======\\n[PASS] passed all tests!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each of these vectors, each index is **processed at a single time step**. So, for the input at time step 0, the model receives the index for the first character in the sequence, and tries to predict the index of the next character.\n",
        "\n",
        "At the next timestep, it does the same thing, but the **RNN considers the information from the previous step, i.e., its updated state, in addition to the current input**."
      ],
      "metadata": {
        "id": "HesPnlOhU4no"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhtkJoJmlPge"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building the Training model\n",
        "The model is based off the [**LSTM architecture**](https://medium.com/analytics-vidhya/lstms-explained-a-complete-technically-accurate-conceptual-guide-with-keras-2a650327e8f2), where a state vector is used to maintain information about the **temporal relationships between consecutive characters**.\n",
        "\n",
        "The final output of the LSTM is then fed into a **fully connected Dense layer** where we'll output a *softmax* over each character in the vocabulary, and then sample from this distribution to predict the next character."
      ],
      "metadata": {
        "id": "GBcT5bi57mGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xFrPsrbCnCD_"
      },
      "outputs": [],
      "source": [
        "def LSTM(rnn_units):\n",
        "  return tf.keras.layers.LSTM(\n",
        "    rnn_units,\n",
        "    return_sequences=True,\n",
        "    recurrent_initializer='glorot_uniform',\n",
        "    recurrent_activation='sigmoid',\n",
        "    stateful=True,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToWjziiFn_u2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        # Layer 1: Embedding layer to transform indices into dense vectors\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "\n",
        "        # Layer 2: LSTM with `rnn_units` number of units.\n",
        "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        # Layer 3: Dense (fully-connected) layer that transforms the LSTM output into the vocabulary size.\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build a simple model with default hyperparameters.\n",
        "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the model\n"
      ],
      "metadata": {
        "id": "mHr5guPMAPhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SpRgQoUoOC6"
      },
      "outputs": [],
      "source": [
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
        "pred = model(x)\n",
        "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
        "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prediction from the untrained model\n",
        "To get actual predictions from the model, output distribution is to be sampled from, which is defined by a softmax over the character vocabulary. This will give the actual character indices.\n",
        "\n",
        "This means a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) is to be used to sample over the example prediction. This gives a prediction of the next character (specifically its index) at each timestep."
      ],
      "metadata": {
        "id": "tTQchSiyAgqg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icx5MmINoXVX"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f6J2lcjodlc"
      },
      "outputs": [],
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model\n",
        "The next character prediction problem can be thought of as a standard classification problem. Given the previous state of the RNN, as well as the input at a given time step, the class of the next character is to be predict -- that is, to actually predict the next character.\n",
        "\n",
        "To train the model on this classification task, a form of the **crossentropy loss (negative log likelihood loss)** can be used. Specifically, the `sparse_categorical_crossentropy` loss is to be used. It utilizes integer targets for categorical classification tasks."
      ],
      "metadata": {
        "id": "Qfea13qiB72c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_h4PsDqogGo",
        "outputId": "c9db7ba0-ef7e-4364-e500-edc5480978e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (32, 10, 83)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.4190063\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the loss function\n",
        "def compute_loss(labels, logits):\n",
        "    # Compute the sparse categorical cross-entropy loss\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "    return loss\n",
        "\n",
        "# Generate some example input data for testing\n",
        "example_input_batch = np.random.randint(0, len(vocab), (32, 10))  # Example shape: (batch_size, sequence_length)\n",
        "\n",
        "# Make predictions with the untrained model\n",
        "pred = model(example_input_batch)\n",
        "\n",
        "# Generate some example labels for testing (same shape as example_input_batch)\n",
        "example_labels = np.random.randint(0, len(vocab), (32, 10))\n",
        "\n",
        "# Compute the loss using the true next characters from the example batch and the predictions\n",
        "example_batch_loss = compute_loss(example_labels, pred)\n",
        "\n",
        "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9EpagFktowT2"
      },
      "outputs": [],
      "source": [
        "### Hyperparameter setting and optimization ###\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Model parameters:\n",
        "params = dict(\n",
        "  num_training_iterations = 3000,\n",
        "  batch_size = 8,\n",
        "  seq_length = 100,\n",
        "  learning_rate = 5e-3,\n",
        "  embedding_dim = 256,\n",
        "  rnn_units = 1024,\n",
        ")\n",
        "\n",
        "# Checkpoint location:\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m659yF1ao3OI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import comet_ml as comet\n",
        "\n",
        "# Define hyperparameters\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Instantiate a new model for training\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "\n",
        "# Instantiate the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Feed the current input into the model and generate predictions\n",
        "        y_hat = model(x)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = compute_loss(y, y_hat)\n",
        "\n",
        "    # Compute the gradients\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # Apply the gradients to the optimizer\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Begin training\n",
        "\n",
        "# Parameters for training\n",
        "params = {\n",
        "    \"num_training_iterations\": 1000,\n",
        "    \"seq_length\": 100,\n",
        "    \"batch_size\": batch_size\n",
        "}\n",
        "\n",
        "# Initialize Comet experiment\n",
        "api_key = \"hce3AJwsDNoJJq1rxvSoGTxwc\"\n",
        "experiment = comet.Experiment(api_key=api_key)\n",
        "\n",
        "history = []\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{iter}\")\n",
        "\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "for iter in tqdm(range(params[\"num_training_iterations\"])):\n",
        "    # Grab a batch and propagate it through the network\n",
        "    x_batch, y_batch = get_batch(vectorized_songs, params[\"seq_length\"], params[\"batch_size\"])\n",
        "    loss = train_step(x_batch, y_batch)\n",
        "\n",
        "    # Log the loss to the Comet interface\n",
        "    experiment.log_metric(\"loss\", loss.numpy().mean(), step=iter)\n",
        "\n",
        "    # Update the progress bar and also visualize within the notebook\n",
        "    history.append(loss.numpy().mean())\n",
        "    plotter.plot(history)\n",
        "\n",
        "    # Save the model weights every 100 iterations\n",
        "    if iter % 100 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(iter=iter))\n",
        "\n",
        "# Save the final trained model and the weights\n",
        "model.save_weights(checkpoint_prefix.format(iter=params[\"num_training_iterations\"] - 1))\n",
        "experiment.end()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yml4osQco5vu"
      },
      "outputs": [],
      "source": [
        "# Rebuild the model using a batch_size=1\n",
        "# Use the same vocab_size, embedding_dim, and rnn_units as used during training\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "# Restore the model weights for the last checkpoint after training\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# Build the model with the new batch size (batch_size=1)\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kAZlL76r8USk"
      },
      "outputs": [],
      "source": [
        "### Prediction of a generated song ###\n",
        "\n",
        "def generate_text(model, start_string, generation_length=1000):\n",
        "    # Evaluation step (generating ABC text using the learned RNN model)\n",
        "\n",
        "    # Convert the start string to numbers (vectorize)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store the results\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    tqdm._instances.clear()\n",
        "\n",
        "    for i in tqdm(range(generation_length)):\n",
        "        # Evaluate the inputs and generate the next character predictions\n",
        "        predictions = model(input_eval)\n",
        "\n",
        "        # Remove the batch dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # Use a multinomial distribution to sample\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the prediction along with the previous hidden state\n",
        "        # as the next inputs to the model\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        # Add the predicted character to the generated text\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azKwOZNI8W4h"
      },
      "outputs": [],
      "source": [
        "### Play back generated songs ###\n",
        "\n",
        "generated_text = generate_text(model, start_string = \"x\", generation_length=1000)\n",
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs):\n",
        "  # Synthesize the waveform from a song\n",
        "  waveform = mdl.lab1.play_song(song)\n",
        "\n",
        "  # If its a valid song (correct syntax), lets play it!\n",
        "  if waveform:\n",
        "    print(\"Generated song\", i)\n",
        "    ipythondisplay.display(waveform)\n",
        "\n",
        "    numeric_data = np.frombuffer(waveform.data, dtype=np.int16)\n",
        "    wav_file_path = f\"output_{i}.wav\"\n",
        "    write(wav_file_path, 88200, numeric_data)\n",
        "\n",
        "    experiment.log_asset(wav_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AK1Ek3IZ8a2X"
      },
      "outputs": [],
      "source": [
        "# when done, end the comet experiment\n",
        "experiment.end()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NNu3HWskD8Zw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNom/4WxH9e+f46cawjdBXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}