{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehulgoyal353/Music-Generation-using-RNN/blob/main/Music_generation_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIgp02gJJ56r"
      },
      "source": [
        "#Importing required libraries\n",
        "This model is trained to learn the patterns in raw sheet music in [ABC notation](https://en.wikipedia.org/wiki/ABC_notation) and then use this model to generate new music.\n",
        "\n",
        "Comet has been used to track the model development and training runs. The personal API key is generated after logging into [Comet ML](https://www.comet.com/docs/v2/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD8wxpLyamHz"
      },
      "outputs": [],
      "source": [
        "!pip install comet_ml > /dev/null 2>&1\n",
        "import comet_ml\n",
        "COMET_API_KEY = \"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "!pip install mitdeeplearning --quiet\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "from scipy.io.wavfile import write\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "\n",
        "assert COMET_API_KEY != \"hce3AJwsDNoJJq1rxvSoGTxwc\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aaIJq9UBV-l"
      },
      "source": [
        "#Downloading and inspecting the dataset\n",
        "This dataset involve a large collection of Irish music. It is downloaded using the mdl library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv71CR1bd9CK"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "songs = mdl.lab1.load_training_data()\n",
        "\n",
        "# Print one of the songs to inspect it in greater detail!\n",
        "example_song = songs[0]\n",
        "print(\"\\nExample song: \")\n",
        "print(example_song)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ttG7GZB_ET"
      },
      "source": [
        "The mdl library also has functions to convert the strings into wav files which can be listened to on colab itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MRMzOEsTfHvb"
      },
      "outputs": [],
      "source": [
        "# Convert the ABC notation to audio file and listen to it\n",
        "mdl.lab1.play_song(example_song)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgiPNkbjChQj"
      },
      "source": [
        "The ABC notation of these songs doesn't only contain information about the notes being played, but **also has the meta information** like the song title, key and tempo. Thus we get the possible characters in the dataset separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ENQrf4YcfU68"
      },
      "outputs": [],
      "source": [
        "# Join our list of song strings into a single string containing all songs\n",
        "songs_joined = \"\\n\\n\".join(songs)\n",
        "\n",
        "# Find all unique characters in the joined string\n",
        "vocab = sorted(set(songs_joined))\n",
        "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up0Nt-CoDXJM"
      },
      "source": [
        "The aim is for the RNN model to learn patterns in ABC music, and then use this model to generate (i.e., predict) a new piece of music based on this learned information.\n",
        "\n",
        "Henceforth, what is required from the model is: **given a character, or a sequence of characters**, what is the **most probable next character**.\n",
        "\n",
        "RNNs maintain an **internal state that depends on previously seen elements**, so **information about all characters seen up until a given moment will be taken into account in generating the prediction**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2htaheVFE_XS"
      },
      "source": [
        "#Vectorization and Processing\n",
        "Before training the RNN model, **numerical representations** of the text based dataset need to be created.\n",
        "\n",
        "For this **two lookup tables** can be created: **one that maps characters to numbers, and a second that maps numbers back to characters.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HmyB4IO_gIbM"
      },
      "outputs": [],
      "source": [
        "### Define numerical representation of text ###\n",
        "\n",
        "# Create a mapping from character to unique index.\n",
        "# For example, to get the index of the character \"d\", we can evaluate `char2idx[\"d\"]`.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "\n",
        "# Create a mapping from indices to characters. This is\n",
        "#  the inverse of char2idx and allows us to convert back\n",
        "#   from unique index to the character in our vocabulary.\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kyWKMm5DgMwj"
      },
      "outputs": [],
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kgryUrP6g0h5"
      },
      "outputs": [],
      "source": [
        "### Vectorize the songs string ###\n",
        "\n",
        "def vectorize_string(string):\n",
        "  # Convert each character in the string to its corresponding index\n",
        "  vectorized = [char2idx[char] for char in string]\n",
        "  # Convert the list to a numpy array\n",
        "  return np.array(vectorized)\n",
        "\n",
        "vectorized_songs = vectorize_string(songs_joined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WIOD3valhNpS"
      },
      "outputs": [],
      "source": [
        "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
        "# check that vectorized_songs is a numpy array\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eERfU26eksbp"
      },
      "outputs": [],
      "source": [
        "### Batch definition to create training examples ###\n",
        "\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  # the length of the vectorized songs string\n",
        "  n = vectorized_songs.shape[0] - 1\n",
        "  # randomly choose the starting indices for the examples in the training batch\n",
        "  idx = np.random.choice(n-seq_length, batch_size)\n",
        "\n",
        "  input_batch = [vectorized_songs[i:i + seq_length] for i in idx]\n",
        "  output_batch = [vectorized_songs[i + 1:i + seq_length + 1] for i in idx]\n",
        "\n",
        "  # x_batch, y_batch provide the true inputs and targets for network training\n",
        "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "  return x_batch, y_batch\n",
        "\n",
        "\n",
        "# Perform some simple tests to make sure your batch function is working properly!\n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args):\n",
        "   print(\"======\\n[FAIL] could not pass tests\")\n",
        "else:\n",
        "   print(\"======\\n[PASS] passed all tests!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VhtkJoJmlPge"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xFrPsrbCnCD_"
      },
      "outputs": [],
      "source": [
        "def LSTM(rnn_units):\n",
        "  return tf.keras.layers.LSTM(\n",
        "    rnn_units,\n",
        "    return_sequences=True,\n",
        "    recurrent_initializer='glorot_uniform',\n",
        "    recurrent_activation='sigmoid',\n",
        "    stateful=True,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ToWjziiFn_u2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        # Layer 1: Embedding layer to transform indices into dense vectors\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "\n",
        "        # Layer 2: LSTM with `rnn_units` number of units.\n",
        "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        # Layer 3: Dense (fully-connected) layer that transforms the LSTM output into the vocabulary size.\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build a simple model with default hyperparameters. You will get the chance to change these later.\n",
        "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0SpRgQoUoOC6"
      },
      "outputs": [],
      "source": [
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
        "pred = model(x)\n",
        "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
        "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "icx5MmINoXVX"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7f6J2lcjodlc"
      },
      "outputs": [],
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N_h4PsDqogGo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the loss function\n",
        "def compute_loss(labels, logits):\n",
        "    # Compute the sparse categorical cross-entropy loss\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "    return loss\n",
        "\n",
        "# Generate some example input data for testing\n",
        "example_input_batch = np.random.randint(0, len(vocab), (32, 10))  # Example shape: (batch_size, sequence_length)\n",
        "\n",
        "# Make predictions with the untrained model\n",
        "pred = model(example_input_batch)\n",
        "\n",
        "# Generate some example labels for testing (same shape as example_input_batch)\n",
        "example_labels = np.random.randint(0, len(vocab), (32, 10))\n",
        "\n",
        "# Compute the loss using the true next characters from the example batch and the predictions\n",
        "example_batch_loss = compute_loss(example_labels, pred)\n",
        "\n",
        "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9EpagFktowT2"
      },
      "outputs": [],
      "source": [
        "### Hyperparameter setting and optimization ###\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Model parameters:\n",
        "params = dict(\n",
        "  num_training_iterations = 3000,  # Increase this to train longer\n",
        "  batch_size = 8,  # Experiment between 1 and 64\n",
        "  seq_length = 100,  # Experiment between 50 and 500\n",
        "  learning_rate = 5e-3,  # Experiment between 1e-5 and 1e-1\n",
        "  embedding_dim = 256,\n",
        "  rnn_units = 1024,  # Experiment between 1 and 2048\n",
        ")\n",
        "\n",
        "# Checkpoint location:\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m659yF1ao3OI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import comet_ml as comet\n",
        "\n",
        "# Define hyperparameters\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Instantiate a new model for training\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "\n",
        "# Instantiate the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Feed the current input into the model and generate predictions\n",
        "        y_hat = model(x)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = compute_loss(y, y_hat)\n",
        "\n",
        "    # Compute the gradients\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # Apply the gradients to the optimizer\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Begin training\n",
        "\n",
        "# Parameters for training\n",
        "params = {\n",
        "    \"num_training_iterations\": 1000,\n",
        "    \"seq_length\": 100,\n",
        "    \"batch_size\": batch_size\n",
        "}\n",
        "\n",
        "# Initialize Comet experiment\n",
        "api_key = \"hce3AJwsDNoJJq1rxvSoGTxwc\"\n",
        "experiment = comet.Experiment(api_key=api_key)\n",
        "\n",
        "history = []\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{iter}\")\n",
        "\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "for iter in tqdm(range(params[\"num_training_iterations\"])):\n",
        "    # Grab a batch and propagate it through the network\n",
        "    x_batch, y_batch = get_batch(vectorized_songs, params[\"seq_length\"], params[\"batch_size\"])\n",
        "    loss = train_step(x_batch, y_batch)\n",
        "\n",
        "    # Log the loss to the Comet interface\n",
        "    experiment.log_metric(\"loss\", loss.numpy().mean(), step=iter)\n",
        "\n",
        "    # Update the progress bar and also visualize within the notebook\n",
        "    history.append(loss.numpy().mean())\n",
        "    plotter.plot(history)\n",
        "\n",
        "    # Save the model weights every 100 iterations\n",
        "    if iter % 100 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(iter=iter))\n",
        "\n",
        "# Save the final trained model and the weights\n",
        "model.save_weights(checkpoint_prefix.format(iter=params[\"num_training_iterations\"] - 1))\n",
        "experiment.end()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yml4osQco5vu"
      },
      "outputs": [],
      "source": [
        "# Rebuild the model using a batch_size=1\n",
        "# Use the same vocab_size, embedding_dim, and rnn_units as used during training\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "# Restore the model weights for the last checkpoint after training\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# Build the model with the new batch size (batch_size=1)\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kAZlL76r8USk"
      },
      "outputs": [],
      "source": [
        "### Prediction of a generated song ###\n",
        "\n",
        "def generate_text(model, start_string, generation_length=1000):\n",
        "    # Evaluation step (generating ABC text using the learned RNN model)\n",
        "\n",
        "    # Convert the start string to numbers (vectorize)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    tqdm._instances.clear()\n",
        "\n",
        "    for i in tqdm(range(generation_length)):\n",
        "        # Evaluate the inputs and generate the next character predictions\n",
        "        predictions = model(input_eval)\n",
        "\n",
        "        # Remove the batch dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # Use a multinomial distribution to sample\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the prediction along with the previous hidden state\n",
        "        # as the next inputs to the model\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        # Add the predicted character to the generated text\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "azKwOZNI8W4h"
      },
      "outputs": [],
      "source": [
        "### Play back generated songs ###\n",
        "\n",
        "generated_text = generate_text(model, start_string = \"x\", generation_length=1000)\n",
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs):\n",
        "  # Synthesize the waveform from a song\n",
        "  waveform = mdl.lab1.play_song(song)\n",
        "\n",
        "  # If its a valid song (correct syntax), lets play it!\n",
        "  if waveform:\n",
        "    print(\"Generated song\", i)\n",
        "    ipythondisplay.display(waveform)\n",
        "\n",
        "    numeric_data = np.frombuffer(waveform.data, dtype=np.int16)\n",
        "    wav_file_path = f\"output_{i}.wav\"\n",
        "    write(wav_file_path, 88200, numeric_data)\n",
        "\n",
        "    # save your song to the Comet interface -- you can access it there\n",
        "    experiment.log_asset(wav_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AK1Ek3IZ8a2X"
      },
      "outputs": [],
      "source": [
        "# when done, end the comet experiment\n",
        "experiment.end()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNqDExdRVyAhm8Jmg47WVdP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}